{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries and settings\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "import random\n",
    "from functools import reduce\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from spotipy import oauth2\n",
    "\n",
    "from kafka import KafkaProducer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    FloatType,\n",
    "    ArrayType,\n",
    ")\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = {\n",
    "    \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0,org.neo4j:neo4j-connector-apache-spark_2.12:5.0.2_for_spark_3\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n",
    "secret = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n",
    "redirect_uri='http://localhost:7777/callback'\n",
    "username = 'vass.zora'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the Authorisation is complete, we just need to `sp` to call the APIs\n",
    "scope = 'user-top-read user-read-private playlist-modify-private playlist-modify-public user-read-currently-playing'\n",
    "token = util.prompt_for_user_token(username, scope, client_id=cid, client_secret=secret, redirect_uri=redirect_uri)\n",
    "\n",
    "if token:\n",
    "    sp = spotipy.Spotify(auth=token)\n",
    "else:\n",
    "    print(\"Can't get token for\", username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to get tracks IDs from a playlist\n",
    "def get_playlist_tracks(username,playlist_id):\n",
    "    results = sp.user_playlist_tracks(username,playlist_id)\n",
    "    tracks = results['items']\n",
    "    while results['next']:\n",
    "        results = sp.next(results)\n",
    "        tracks.extend(results['items'])\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting playlist IDs from each of Spotify's playlists #TODO add to method\n",
    "playlists = sp.user_playlists(username)\n",
    "spotify_playlist_ids = []\n",
    "while playlists:\n",
    "    for i, playlist in enumerate(playlists['items']):\n",
    "        spotify_playlist_ids.append(playlist['uri'][-22:])\n",
    "    if playlists['next']:\n",
    "        playlists = sp.next(playlists)\n",
    "    else:\n",
    "        playlists = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_tracks = sp.current_user_playing_track()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_id_mood_dict = {\n",
    "    'sad': '37i9dQZF1DX3rxVfibe1L0',\n",
    "    'happy': '37i9dQZF1DX4uPi2roRUwU',\n",
    "    'chill': '37i9dQZF1DWWQRwui0ExPn',\n",
    "    'angry': '37i9dQZF1DX3ND264N08pv',\n",
    "    'romantic': '37i9dQZF1DX7rOY2tZUw1k',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "moods = ['sad', 'happy', 'chill', 'angry', 'romantic']\n",
    "\n",
    "# Getting tracks from each playlist\n",
    "tracks = []\n",
    "audio_features = []\n",
    "for mood in moods:\n",
    "    current_tracks = get_playlist_tracks(username, playlist_id_mood_dict[mood])\n",
    "    for track in current_tracks:\n",
    "        tracks.append(track)\n",
    "    for track in current_tracks:\n",
    "        current_audio = sp.audio_features(track['track']['id'])[0]\n",
    "        current_audio['mood'] = moods.index(mood)\n",
    "        audio_features.append(current_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/31 16:55:12 WARN Utils: Your hostname, HP-Elite830 resolves to a loopback address: 127.0.1.1; using 10.224.1.29 instead (on interface wlp1s0)\n",
      "23/05/31 16:55:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/home/vaszo/.local/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/vaszo/.ivy2/cache\n",
      "The jars for the packages stored in: /home/vaszo/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      "org.neo4j#neo4j-connector-apache-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-1b7d6031-8387-44a8-b2eb-f02d21c8a59d;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.4.0 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.4.0 in central\n",
      "\tfound org.apache.kafka#kafka-clients;3.3.2 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.9.1 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.6 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in local-m2-cache\n",
      "\tfound org.neo4j#neo4j-connector-apache-spark_2.12;5.0.2_for_spark_3 in central\n",
      "\tfound org.neo4j#neo4j-connector-apache-spark_2.12_common;5.0.2 in central\n",
      "\tfound org.neo4j.driver#neo4j-java-driver;4.4.11 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.4 in central\n",
      "\tfound org.apache.xbean#xbean-asm6-shaded;4.10 in central\n",
      "\tfound org.neo4j#neo4j-cypher-dsl;2020.1.4 in central\n",
      "\tfound org.apiguardian#apiguardian-api;1.1.0 in central\n",
      ":: resolution report :: resolve 1191ms :: artifacts dl 60ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from local-m2-cache in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;3.3.2 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.4.0 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.4.0 from central in [default]\n",
      "\torg.apache.xbean#xbean-asm6-shaded;4.10 from central in [default]\n",
      "\torg.apiguardian#apiguardian-api;1.1.0 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.neo4j#neo4j-connector-apache-spark_2.12;5.0.2_for_spark_3 from central in [default]\n",
      "\torg.neo4j#neo4j-connector-apache-spark_2.12_common;5.0.2 from central in [default]\n",
      "\torg.neo4j#neo4j-cypher-dsl;2020.1.4 from central in [default]\n",
      "\torg.neo4j.driver#neo4j-java-driver;4.4.11 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.4 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.6 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.9.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   18  |   0   |   0   |   0   ||   18  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-1b7d6031-8387-44a8-b2eb-f02d21c8a59d\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 18 already retrieved (0kB/39ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/31 16:55:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"Final assignment\")\n",
    "    .config(\"spark.jars.packages\", \",\".join(packages))\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=\"localhost:9092\")\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<kafka.producer.future.FutureRecordMetadata at 0x7fee2c944af0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "producer.send(\"tracks_topic\", b\"\")\n",
    "producer.send(\"number_of_clusters\", b\"\")\n",
    "producer.send(\"audio_features_topic\", b\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.readStream.format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n",
    "    .option(\"subscribe\", \"tracks_topic, number_of_clusters, audio_features_topic\")\n",
    "    .option(\"startingOffsets\", \"latest\")\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_schema = StructType(\n",
    "    [\n",
    "        StructField(\"id\", StringType()),\n",
    "        StructField(\"name\", StringType()),\n",
    "        StructField(\"artists\", ArrayType(\n",
    "            StructType([\n",
    "                StructField(\"id\", StringType()),\n",
    "                StructField(\"name\", StringType())\n",
    "            ])\n",
    "        )),\n",
    "        StructField(\"duration_ms\", StringType())\n",
    "    ]\n",
    ")       \n",
    "\n",
    "\n",
    "number_of_clusters_schema = StructType(\n",
    "    [\n",
    "        StructField(\"K\", IntegerType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "audio_features_schema = StructType(\n",
    "    [\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"danceability\", FloatType(), True),\n",
    "        StructField(\"energy\", FloatType(), True),\n",
    "        StructField(\"key\", IntegerType(), True),\n",
    "        StructField(\"loudness\", FloatType(), True),\n",
    "        StructField(\"mode\", IntegerType(), True),\n",
    "        StructField(\"speechiness\", FloatType(), True),\n",
    "        StructField(\"acousticness\", FloatType(), True),\n",
    "        StructField(\"instrumentalness\", FloatType(), True),\n",
    "        StructField(\"liveness\", FloatType(), True),\n",
    "        StructField(\"valence\", FloatType(), True),\n",
    "        StructField(\"tempo\", FloatType(), True),\n",
    "        StructField(\"mood\", IntegerType(), True),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_stream = (\n",
    "    df.selectExpr(\"CAST(value AS STRING)\")\n",
    "    .filter(\"topic = 'tracks_topic'\")\n",
    "    .select(from_json(\"value\", tracks_schema).alias(\"data\"))\n",
    "    .select(\"data.*\")\n",
    ")\n",
    "\n",
    "number_of_clusters_stream = (\n",
    "    df.selectExpr(\"CAST(value AS STRING)\")\n",
    "    .select(from_json(\"value\", number_of_clusters_schema).alias(\"data\"))\n",
    "    .select(\"data.*\")\n",
    ")\n",
    "\n",
    "audio_features_stream = (\n",
    "    df.selectExpr(\"CAST(value AS STRING)\")\n",
    "    .select(from_json(\"value\", audio_features_schema).alias(\"data\"))\n",
    "    .select(\"data.*\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_query = (\n",
    "    tracks_stream.writeStream.format(\"memory\")\n",
    "    .queryName(\"tracks\")\n",
    "    .start()\n",
    ")\n",
    "\n",
    "number_of_clusters_query = (\n",
    "    number_of_clusters_stream.writeStream.format(\"memory\")\n",
    "    .queryName(\"number_of_clusters\")\n",
    "    .start()\n",
    ")\n",
    "\n",
    "audio_features_query = (\n",
    "    audio_features_stream.writeStream.format(\"memory\")\n",
    "    .queryName(\"audio_features\")\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracks_query.stop()\n",
    "# number_of_clusters_query.stop()\n",
    "# audio_features_query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for track in tracks:\n",
    "    producer.send(\"tracks_topic\", json.dumps(track['track']).encode(\"utf-8\"))\n",
    "\n",
    "for audio in audio_features:\n",
    "    producer.send(\"audio_features_topic\", json.dumps(audio).encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tracks_spark = spark.sql(\"select * from tracks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+----------------------------------------------------+--------------------------------------------------------------------------------------+-----------+\n",
      "|id                    |name                                                |artists                                                                               |duration_ms|\n",
      "+----------------------+----------------------------------------------------+--------------------------------------------------------------------------------------+-----------+\n",
      "|0rzaRSujxA0bKyjJl6vHYq|Satellite                                           |[{6KImCVD70vtIoJWnq6nGn3, Harry Styles}]                                              |218577     |\n",
      "|40SBS57su9xLiE1WqkXOVr|Afraid To Feel                                      |[{0HxX6imltnNXJyQhu4nsiO, LF SYSTEM}]                                                 |177524     |\n",
      "|1AAexX86yX7YO2llLMosU8|Treeology                                           |[{1mOiWC7OH9ANUtt3vd0A10, Shuko}, {3fMYtQwkblUGOAto35b82Y, Beats for Trees}]          |135853     |\n",
      "|6z0i14WyHNAdQq889bnSu8|The Roots - Official Harmony of Hardcore 2023 Anthem|[{7oX7rzli18XsB2WFd88oW4, Dj Mad Dog}, {6lnLf5Y8uD0mP5dC0gXouZ, Dave Revan}]          |235734     |\n",
      "|3ERa3mEeOnrh2Mc47qM6T1|Halo                                                |[{6vWDO969PvNqNYHIOW5v0m, Beyoncé}]                                                   |261640     |\n",
      "|0rzaRSujxA0bKyjJl6vHYq|Satellite                                           |[{6KImCVD70vtIoJWnq6nGn3, Harry Styles}]                                              |218577     |\n",
      "|1l4iQsOZ5sOXZPMQLvouaB|Coast (feat. Anderson .Paak)                        |[{5p7f24Rk5HkUZsaS3BLG5F, Hailee Steinfeld}, {3jK9MiCrA42lLAdMGUZpwa, Anderson .Paak}]|166720     |\n",
      "|5jQI2r1RdgtuT8S3iG8zFC|Lavender Haze                                       |[{06HL4z0CvFAxyc27GXpf02, Taylor Swift}]                                              |202395     |\n",
      "|6maTPqynTmrkWIralgGaoP|If We Ever Broke Up                                 |[{311uEW9rt5g2NmzjGEKS2E, Mae Stephens}]                                              |142758     |\n",
      "|52Rfxu5AUNMV1qhhC2ZCkb|Meltdown                                            |[{1Hsdzj7Dlq2I7tHP7501T4, Niall Horan}]                                               |153037     |\n",
      "+----------------------+----------------------------------------------------+--------------------------------------------------------------------------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tracks_spark.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_spark = spark.sql(\"select * from audio_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------+------+----+--------+----+-----------+------------+----------------+--------+-------+-------+----+\n",
      "|id                    |danceability|energy|key |loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|tempo  |mood|\n",
      "+----------------------+------------+------+----+--------+----+-----------+------------+----------------+--------+-------+-------+----+\n",
      "|0rzaRSujxA0bKyjJl6vHYq|null        |null  |null|null    |null|null       |null        |null            |null    |null   |null   |null|\n",
      "|40SBS57su9xLiE1WqkXOVr|null        |null  |null|null    |null|null       |null        |null            |null    |null   |null   |null|\n",
      "|0rzaRSujxA0bKyjJl6vHYq|0.576       |0.457 |0   |-6.473  |1   |0.0304     |0.143       |3.05E-5         |0.0917  |0.301  |138.984|0   |\n",
      "|1l4iQsOZ5sOXZPMQLvouaB|0.701       |0.875 |11  |-4.1    |1   |0.0757     |0.0262      |7.32E-6         |0.137   |0.84   |111.976|0   |\n",
      "|5jQI2r1RdgtuT8S3iG8zFC|0.733       |0.436 |10  |-10.489 |1   |0.08       |0.258       |5.73E-4         |0.157   |0.0976 |96.985 |0   |\n",
      "|6maTPqynTmrkWIralgGaoP|0.898       |0.732 |7   |-3.982  |1   |0.0427     |0.621       |1.29E-5         |0.0908  |0.96   |115.955|0   |\n",
      "|52Rfxu5AUNMV1qhhC2ZCkb|0.493       |0.855 |11  |-4.029  |1   |0.0967     |0.00673     |0.0             |0.38    |0.754  |179.039|0   |\n",
      "|5c6lM2zjAF6MFoD8C1hiBr|0.552       |0.873 |0   |-6.065  |1   |0.0464     |0.00137     |2.73E-4         |0.0966  |0.62   |125.059|0   |\n",
      "|6dgUya35uo964z7GZXM07g|0.74        |0.697 |8   |-4.912  |1   |0.034      |0.0268      |0.0             |0.224   |0.732  |138.992|0   |\n",
      "|2rmwqU7yzTvzkiaRV53DpT|0.721       |0.769 |7   |-4.111  |1   |0.105      |0.0922      |0.0             |0.0817  |0.915  |155.932|0   |\n",
      "+----------------------+------------+------+----+--------+----+-----------+------------+----------------+--------+-------+-------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "audio_features_spark.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df, assembler, scaler):\n",
    "    df = df.dropna()\n",
    "    df = df.drop('id')\n",
    "    assembled_data = assembler.transform(df)\n",
    "    scaler_model = scaler.fit(assembled_data)\n",
    "    scaled_data = scaler_model.transform(assembled_data)\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo'], outputCol = 'features')\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scaled_train = transform_data(audio_features_spark, vectorAssembler, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\", labelCol=\"mood\", featuresCol=\"scaledFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nb.fit(scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_song = None\n",
    "while True:\n",
    "    current_track = sp.current_user_playing_track()\n",
    "    if current_track is not None:\n",
    "        if prev_song != current_track['item']['id']:\n",
    "            current_audio_features = sp.audio_features(current_track['item']['id'])[0]\n",
    "            scaled_current_audio_features = transform_data(spark.createDataFrame([current_audio_features]), vectorAssembler, scaler)\n",
    "            prediction = model.predict(scaled_current_audio_features.select('scaledFeatures').collect()[0][0])\n",
    "            producer.send(\"number_of_clusters\", moods[int(prediction)].encode(\"utf-8\"))\n",
    "            prev_song = current_track['item']['id']\n",
    "    else:\n",
    "        prev_song = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
